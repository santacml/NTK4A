{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate the NTK of a RNN in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:58:21.854150Z",
     "start_time": "2020-06-17T20:58:20.614135Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:58:21.860504Z",
     "start_time": "2020-06-17T20:58:21.855846Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import clone_grads, paramdot, VErf3, VDerErf3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider the RNN with forward and backward propagation defined by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN.png](images/RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN_sampling.png](images/RNN_sampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Finite-Width Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:58:21.896596Z",
     "start_time": "2020-06-17T20:58:21.862530Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class BidirectionalRNNClassifier(nn.Module):\n",
    "    def __init__(self, indim, statedim, outdim=1, nonlin=torch.erf, varu=1, varw=1, varb=0, varv=1,\n",
    "                avgpool=False, debug=False):\n",
    "        super().__init__()\n",
    "        self.varu = varu\n",
    "        self.varw = varw\n",
    "        self.varb = varb\n",
    "        self.varv = varv\n",
    "        self.nonlin = nonlin\n",
    "        self.avgpool = avgpool\n",
    "        self.debug = debug\n",
    "        self.W = nn.Parameter(torch.randn(statedim, statedim))\n",
    "        self.U = nn.Parameter(torch.randn(indim, statedim))\n",
    "        self.b = nn.Parameter(torch.randn(statedim))\n",
    "        self.v = nn.Parameter(torch.randn(statedim, outdim))\n",
    "        self.randomize()\n",
    "        \n",
    "    def forward(self, inp, initstate=0):\n",
    "        '''\n",
    "        Input:\n",
    "            inp: (batchsize, seqlen, indim)\n",
    "        Output:\n",
    "            out: (batchsize, outdim)\n",
    "        '''\n",
    "        indim = self.U.shape[0]\n",
    "        statedim = self.U.shape[1]\n",
    "        embed = torch.einsum(\n",
    "            'ijk,kl->ijl', inp, self.U) / np.sqrt(indim) + self.b\n",
    "        seqlen = inp.shape[1]\n",
    "        statef = initstate\n",
    "        stateb = initstate\n",
    "        self._states = []\n",
    "        self.hs = []\n",
    "        for i in range(seqlen):\n",
    "            hf = embed[:, i] + statef\n",
    "            statef = self.nonlin(hf)\n",
    "            hb = embed[:, seqlen-1-i] + stateb\n",
    "            stateb = self.nonlin(hb)\n",
    "\n",
    "            #self._states.append(torch.cat((statef, stateb),1))\n",
    "            self._states.append(statef)\n",
    "            if self.debug:\n",
    "                state.retain_grad()\n",
    "            # _states[i] = s^{i+1}\n",
    "                self.hs.append(h)\n",
    "            \n",
    "            if i < seqlen - 1:\n",
    "                statef = statef @ self.W / np.sqrt(statedim)\n",
    "                stateb = stateb @ self.W / np.sqrt(statedim)\n",
    "            else:\n",
    "                if self.avgpool:\n",
    "                    meanstate = sum(self._states) / len(self._states)\n",
    "                    return meanstate @ self.v / np.sqrt(statedim)\n",
    "                else:\n",
    "                    #return torch.cat((statef, stateb),1) @ self.v / np.sqrt(statedim)\n",
    "                    return statef @ self.v / np.sqrt(statedim)\n",
    "        \n",
    "    def randomize(self, varu=None, varw=None, varb=None, varv=None):\n",
    "        varu = varu or self.varu\n",
    "        varw = varw or self.varw\n",
    "        varb = varb or self.varb\n",
    "        varv = varv or self.varv\n",
    "        with torch.no_grad():\n",
    "            self.W.normal_(std=np.sqrt(varw))\n",
    "            self.U.normal_(std=np.sqrt(varu))\n",
    "            self.v.normal_(std=np.sqrt(varv))\n",
    "            if varb > 0:\n",
    "                self.b.normal_(std=np.sqrt(varb))\n",
    "            else:\n",
    "                self.b.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:58:21.923581Z",
     "start_time": "2020-06-17T20:58:21.898357Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def simrnn_ntk(inputseqs, width, phi, varw=1, varu=1, varb=0, varv=1, seed=None, avgpool=False, debug=False):\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    indim = inputseqs[0].shape[1]\n",
    "    rnn = BidirectionalRNNClassifier(indim, width, nonlin=phi,\n",
    "                              varw=varw, varu=varu, varb=varb, varv=varv,\n",
    "                              avgpool=avgpool, debug=debug)\n",
    "    grads = []\n",
    "    sgrads = []\n",
    "    states = []\n",
    "    hs = []\n",
    "    for seq in inputseqs:\n",
    "        out = rnn(seq.unsqueeze(0))\n",
    "        out.backward()\n",
    "        grads.append(clone_grads(rnn))\n",
    "        if debug:\n",
    "            # shape time x dim_s\n",
    "            sgrads.append(clone_sgrads(rnn))\n",
    "            states.append(clone_states(rnn))\n",
    "            hs.append(clone_hs(rnn))\n",
    "        rnn.zero_grad()\n",
    "        \n",
    "    batchsize = len(inputseqs)\n",
    "    \n",
    "    ntk = torch.zeros(batchsize, batchsize)\n",
    "    for i in range(batchsize):\n",
    "        for j in range(0, i+1):\n",
    "            ntk[i, j] = ntk[j, i] = paramdot(grads[i], grads[j])\n",
    "    \n",
    "    if not debug:\n",
    "        return dict(ntk=ntk)\n",
    "    \n",
    "    dscov = torch.zeros(batchsize, batchsize).tolist()\n",
    "    scov = torch.zeros(batchsize, batchsize).tolist()\n",
    "    hhcov = torch.zeros(batchsize, batchsize).tolist()\n",
    "    for i in range(batchsize):\n",
    "        for j in range(0, i+1):\n",
    "            dscov[i][j] = (sgrads[i] @ sgrads[j].T).numpy()\n",
    "            dscov[j][i] = dscov[i][j].T\n",
    "            scov[i][j] = (states[i] @ states[j].T).numpy() / states[i].shape[-1]\n",
    "            scov[j][i] = scov[i][j].T\n",
    "            hhcov[i][j] = (hs[i] @ hs[j].T).numpy() / hs[i].shape[-1]\n",
    "            hhcov[j][i] = hhcov[i][j].T\n",
    "    return dict(ntk=ntk, dscov=np.block(dscov), scov=np.block(scov), hhcov=np.block(hhcov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Infinite-Width NTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Consider two input sequences $\\xi = \\{\\xi^1, \\ldots, x^T \\in \\mathbb R^d\\}$ and $\\bar \\xi = \\{\\bar \\xi^1, \\ldots, \\bar \\xi^{\\bar T} \\in \\mathbb R^d \\}$.\n",
    "We abbreviate $s^t = s^t(\\xi)$ and $\\bar s^t = s^t(\\bar \\xi)$, and likewise for other vectors $g^t, u^t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The infinite-width NTK then depends on the inner products\n",
    "$$C^{s^t, \\bar s^r} = \\lim_{n\\to\\infty} n^{-1} s^{t\\top} \\bar s^r,\\quad D^{g^t, \\bar g^r} = \\lim_{n\\to\\infty} n^{-1} dg^{t\\top} d\\bar g^r$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![RNN_forward_backward.png](images/RNN_forward_backward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![RNN_LastState.png](images/RNN_LastState.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![RNN_AvgPool.png](images/RNN_AvgPool.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![RNN_NTK.png](images/RNN_NTK.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:58:21.960684Z",
     "start_time": "2020-06-17T20:58:21.925334Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rnnntk_batch(ingram, Vphi3, Vderphi3,\n",
    "    varw=1, varu=1, varb=0, varv=1, avgpool=False):\n",
    "    ''' Compute the RNN-NTK over a batch of sequences of the same length\n",
    "    Inputs:\n",
    "        `ingram`: dimension-normalized Gram matrix between all tokens across all input sequences\n",
    "            of shape [batchsize, batchsize, seqlen, seqlen]\n",
    "        `Vphi3`: V-transform of nonlin that takes in 3 input arrays (cov, var1, var2)\n",
    "        `Vderphi3`: V-transform of nonlin derivative that takes in 3 input arrays (cov, var1, var2)\n",
    "        `varw`: variance of state-to-state weights\n",
    "        `varu`: variance of input-to-state weights\n",
    "        `varb`: variance of biases\n",
    "        `varv`: variance of output weights\n",
    "        `avgpool`: if True, output is the average of all states multiplied by output weights.\n",
    "            Otherwise, output is just the last state multiplied by output weigths.\n",
    "    Outputs:\n",
    "        a dictionary of kernels\n",
    "        output['ntk'] gives the NTK\n",
    "        '''\n",
    "    seqlen = ingram.shape[-1]\n",
    "    batchsize = ingram.shape[0]\n",
    "    # hcov[ia, jb] = < h^(i+2,a), h^(j+2,b) >\n",
    "    hcov = np.zeros(ingram.shape)\n",
    "    # hhcov[ia, jb] = < \\tilde h^(i+1,a), \\tilde h^(j+1,b) >\n",
    "    hhcov = np.zeros(ingram.shape)\n",
    "    hhcov[..., 0, :] = varu * ingram[..., 0, :] + varb\n",
    "    hhcov[..., :, 0] = varu * ingram[..., :, 0] + varb\n",
    "    # fill in zeroed entries\n",
    "    def reflect(t):\n",
    "        return np.where(t==0, np.moveaxis(t, [0, 2], [1, 3]), t)\n",
    "    def hhcov_prep(i=None, b=0):\n",
    "        if i is None:\n",
    "            d = np.einsum('aaii->ai', hhcov)\n",
    "            return np.broadcast_arrays(\n",
    "                hhcov,\n",
    "                d.reshape(batchsize, 1, seqlen, 1),\n",
    "                d.reshape(1, batchsize, 1, seqlen)\n",
    "            )\n",
    "        return np.broadcast_arrays(\n",
    "            hhcov[..., i, b:i+1],\n",
    "            np.diag(hhcov[..., i, i]).reshape(batchsize, 1, 1),\n",
    "            np.einsum('aaii->ai', hhcov[..., b:i+1, b:i+1]).reshape(1, batchsize, i+1-b)\n",
    "        )\n",
    "    def Vderphi(mat):\n",
    "        d = np.diag(mat)\n",
    "        return Vderphi3(mat, d.reshape(-1, 1), d.reshape(1, -1))\n",
    "    \n",
    "    for i in range(0, seqlen):\n",
    "        hcov[..., i, :i+1] = varw * Vphi3(*hhcov_prep(i))\n",
    "        if i < seqlen - 1:\n",
    "            hhcov[..., i+1, 1:i+2] = hcov[..., i, :i+1] + varu * ingram[..., i+1, 1:i+2] + varb\n",
    "    hhcov = reflect(hhcov)\n",
    "    hcov = reflect(hcov)\n",
    "    scov = varw**-1 * hcov\n",
    "    \n",
    "    if not avgpool:\n",
    "        dhcov = np.zeros([batchsize, batchsize, seqlen+1])\n",
    "        dhcov[..., -1] = varv\n",
    "        for i in range(seqlen-1, -1, -1):\n",
    "            dhcov[..., i] = varw * Vderphi(hhcov[..., i, i]) * dhcov[..., i+1]\n",
    "        dhcov /= varw\n",
    "        dhcov = dhcov[..., :-1]\n",
    "        \n",
    "        buf = np.einsum('abii->abi', ingram) + 1\n",
    "        buf[..., 1:] += np.einsum('abii->abi', scov[..., :-1, :-1])\n",
    "        ntk = np.einsum('abi,abi->ab', dhcov, buf)\n",
    "        ntk += scov[..., -1, -1]\n",
    "        return ntk\n",
    "\n",
    "\n",
    "    # dscov[ia, jb] = <ds^(i+1,a), ds^(j+1,b)>\n",
    "    dscov = np.zeros(ingram.shape)\n",
    "    dscov[..., :, -1] = dscov[..., -1, :] = varv\n",
    "    for i in range(seqlen-1, 0, -1):\n",
    "        dscov[..., i-1, :i] = varw * Vderphi3(*hhcov_prep(i, 1)) * dscov[..., i, 1:i+1] + varv\n",
    "    dscov = reflect(dscov)\n",
    "\n",
    "    # dhcov[ia, jb] = <d\\tilde h^(i+1,a), d\\tilde h^(j+1,b)>\n",
    "    dhcov = Vderphi3(*hhcov_prep()) * dscov\n",
    "    \n",
    "    buf = ingram + 1\n",
    "    buf[..., 1:, 1:] += scov[..., :-1, :-1]\n",
    "    ntk = np.einsum('abij,abij->ab', dhcov, buf)\n",
    "    ntk += np.sum(scov, axis=(-1, -2))\n",
    "    return dict(ntk=ntk / seqlen**2, dscov=dscov, scov=scov, hcov=hcov, hhcov=hhcov)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The below function computes the NTK even when sequences have different lengths, but is not as computationally efficient as the batched function above. We will not use it here but we present it for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:58:21.994182Z",
     "start_time": "2020-06-17T20:58:21.962316Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rnnntk(ingram, inputidxs, Vphi3, Vderphi3,\n",
    "    varw=1, varu=1, varb=0, varv=1,\n",
    "    maxlength=None):\n",
    "    '''Compute the RNN-NTK over a batch of sequences of the different lengths\n",
    "    Inputs:\n",
    "        `ingram`: dimension-normalized Gram matrix between all tokens across all input sequences\n",
    "        `inputidxs`: indices of `ingram` that indicate starts of input sequences\n",
    "        `Vphi3`: V transform of the nonlinearity of the RNN (e.g. arcsin for step function, etc)\n",
    "        `varw`: variance of state-to-state weights\n",
    "        `varu`: variance of input-to-state weights\n",
    "        `varb`: variance of biases\n",
    "        `varv`: variance of output weights\n",
    "        `maxlength`: max length of all sequences. Default: None.\n",
    "            In this case, it is calculated from `inputidxs`\n",
    "    Outputs:\n",
    "        a dictionary of kernels\n",
    "        output['ntk'] gives the NTK\n",
    "    '''\n",
    "    if maxlength is None:\n",
    "        maxlength = 0\n",
    "        for i in range(len(inputidxs)-1):\n",
    "            maxlength = max(maxlength, inputidxs[i+1]-inputidxs[i])\n",
    "\n",
    "    # hcov[ia, jb] = < h^(i+2,a), h^(j+2,b) >\n",
    "    hcov = np.zeros(ingram.shape)\n",
    "    # hhcov[ia, jb] = < h^(i+1,a), h^(j+1,b) >\n",
    "    hhcov = np.zeros(ingram.shape)\n",
    "    for _ in range(maxlength):\n",
    "        hhcov[1:, 1:] = hcov[:-1, :-1]\n",
    "        hhcov[inputidxs, :] = hhcov[:, inputidxs] = 0\n",
    "        hhcov += varu * ingram + varb\n",
    "        hcov = varw * Vphi3(hhcov)\n",
    "    # scov[ia, jb] = < s^(i+1,a), s^(j+1,b) >\n",
    "    scov = varw**-1 * hcov\n",
    "    hhcov[1:, 1:] = hcov[:-1, :-1]\n",
    "    hhcov[inputidxs, :] = hhcov[:, inputidxs] = 0\n",
    "    hhcov += varu * ingram + varb\n",
    "    \n",
    "    # dscov[ia, jb] = <ds^(i+1,a), ds^(j+1,b)>\n",
    "    dscov = np.zeros(ingram.shape)\n",
    "    # endidxs = indices of the ends of sentences\n",
    "    endidxs = list(inputidxs)[1:]\n",
    "    endidxs = np.array(endidxs + [0]) - 1\n",
    "    for _ in range(maxlength):\n",
    "        dscov[endidxs, :] = dscov[:, endidxs] = 0\n",
    "        idxs = np.meshgrid(endidxs, endidxs)\n",
    "        # setting <ds^(-1,a), ds^(-1,b)> = varv\n",
    "        dscov[idxs[0].reshape(-1), idxs[1].reshape(-1)] = varv\n",
    "        # <ds^(i+1,a), ds^(j+1,b)> = varw * Vderphi3(h^(i+1,a), h^(j+1,b)) * <ds^(i+2,a), ds^(j+2,b)>\n",
    "        dscov[:-1, :-1] = varw * Vderphi3(hhcov[1:, 1:]) * dscov[1:, 1:]\n",
    "    dscov[endidxs, :] = dscov[:, endidxs] = 0\n",
    "    idxs = np.meshgrid(endidxs, endidxs)\n",
    "    dscov[idxs[0].reshape(-1), idxs[1].reshape(-1)] = varv\n",
    "    \n",
    "    # dhcov[ia, jb] = <d\\tilde h^(i+1,a), d\\tilde h^(j+1,b)>\n",
    "    dhcov = Vderphi3(hhcov) * dscov\n",
    "    \n",
    "    # shifted_scov[ia, jb] = < s^(i,a), s^(j,b) >\n",
    "    shifted_scov = np.zeros(ingram.shape)\n",
    "    shifted_scov[1:, 1:] = scov[:-1, :-1]\n",
    "    shifted_scov[inputidxs, :] = shifted_scov[:, inputidxs] = 0\n",
    "    prd = dhcov * (ingram + shifted_scov + 1)\n",
    "\n",
    "    \n",
    "    ntk = np.zeros([len(inputidxs), len(inputidxs)])\n",
    "    # can't find a vectorized implementation for the following\n",
    "    for i in range(len(inputidxs)):\n",
    "        for j in range(len(inputidxs)):\n",
    "            ei = endidxs[i] + 1 if endidxs[i] != -1 else prd.shape[0]\n",
    "            ej = endidxs[j] + 1 if endidxs[j] != -1 else prd.shape[0]\n",
    "            ntk[i, j] = np.sum(\n",
    "                prd[inputidxs[i]:ei,\n",
    "                    inputidxs[j]:ej]\n",
    "            ) + scov[endidxs[i], endidxs[j]]\n",
    "    return dict(ntk=ntk, dscov=dscov, scov=scov, hcov=hcov, hhcov=hhcov)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Theory vs Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We verify that as width increases, the empirical finite-width NTK converges to the theoretical infinite-width NTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:58:22.976287Z",
     "start_time": "2020-06-17T20:58:21.995796Z"
    },
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Files already downloaded and verified\n"
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We treat the first 5 pixels (3 channels each) as the \"tokens\" in a sequence of 5. We use the first 2 images from CIFAR10 for our 2 sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:58:32.817691Z",
     "start_time": "2020-06-17T20:58:22.978453Z"
    },
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = 2\n",
    "T = 5\n",
    "\n",
    "inps = torch.stack([v[0].reshape(3, -1)[:, :T].T for i, v in enumerate(trainset)\n",
    "                 if i < M]).numpy()\n",
    "inpcov = np.einsum('ais,bjs->aibj', inps, inps) / inps.shape[-1]\n",
    "inpcov = np.moveaxis(inpcov, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:58:32.822207Z",
     "start_time": "2020-06-17T20:58:32.819402Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "varw = 1\n",
    "varu = 2\n",
    "varb = 0.2\n",
    "varv = 1\n",
    "avgpool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:58:32.841304Z",
     "start_time": "2020-06-17T20:58:32.823918Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-2db2242b8fb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mthcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnnntk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minpcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVErf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVDerErf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvaru\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ntk'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;31m#thcov = rnnntk_batch(inpcov, VErf3, VDerErf3, varw, varu, varb, varv, avgpool=True)['ntk']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-88-ecf11c0e217a>\u001b[0m in \u001b[0;36mrnnntk\u001b[1;34m(ingram, inputidxs, Vphi3, Vderphi3, varw, varu, varb, varv, maxlength)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mei\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mendidxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mendidxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mprd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mej\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mendidxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mendidxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mprd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             ntk[i, j] = np.sum(\n\u001b[0m\u001b[0;32m     72\u001b[0m                 prd[inputidxs[i]:ei,\n\u001b[0;32m     73\u001b[0m                     inputidxs[j]:ej]\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "\n",
    "def VErf(cov):\n",
    "    '''\n",
    "    Computes E[erf(z) erf(z)^T | z ~ N(0, `cov`)]\n",
    "    where z is a multivariate Gaussian with mean 0 and covariance `cov`\n",
    "\n",
    "    Inputs:\n",
    "        `cov`: An array where the last 2 dimensions contain covariance matrix of z (and the first dimensions are \"batch\" dimensions)\n",
    "    Output:\n",
    "        a numpy array of the same shape as `cov` that equals the\n",
    "        expectation above in the last 2 dimensions.\n",
    "    '''\n",
    "    ll = list(range(cov.shape[-1]))\n",
    "    d = np.sqrt(cov[..., ll, ll] + 0.5)\n",
    "\n",
    "    c = d[..., None]**(-1) * cov * d[..., None, :]**(-1)\n",
    "    return 2./np.pi * np.arcsin(np.clip(c, -1, 1))\n",
    "\n",
    "\n",
    "def VDerErf(cov):\n",
    "    '''\n",
    "    Computes E[erf'(z) erf'(z)^T | z ~ N(0, `cov`)]\n",
    "    where erf' is the derivative of erf and\n",
    "    z is a multivariate Gaussian with mean 0 and covariance `cov`\n",
    "\n",
    "    Inputs:\n",
    "        `cov`: An array where the last 2 dimensions contain covariance matrix of z (and the first dimensions are \"batch\" dimensions)\n",
    "    Output:\n",
    "        a numpy array of the same shape as `cov` that equals the\n",
    "        expectation above in the last 2 dimensions.\n",
    "    '''\n",
    "    ll = list(range(cov.shape[-1]))\n",
    "    d = np.sqrt(cov[..., ll, ll])\n",
    "    dd = 1 + 2 * d\n",
    "    return 4/np.pi * (dd[..., None] * dd[..., None, :] - 4 * cov**2)**(-1./2)\n",
    "\n",
    "thcov = rnnntk(inpcov, [0, 2], VErf, VDerErf, varw, varu, varb, varv)['ntk']\n",
    "#thcov = rnnntk_batch(inpcov, VErf3, VDerErf3, varw, varu, varb, varv, avgpool=True)['ntk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:58:32.863597Z",
     "start_time": "2020-06-17T20:58:32.842856Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def NTK_theory_vs_sim(inpseqs, infntk, varw, varu, varb, avgpool,\n",
    "                      nonlin=torch.erf,\n",
    "                      log2widthmin=6, log2widthmax=15, nseeds=10):\n",
    "    if isinstance(inpseqs, np.ndarray):\n",
    "        inpseqs = torch.from_numpy(inpseqs).float()\n",
    "    widths = 2**np.arange(log2widthmin, log2widthmax)\n",
    "    mysimcovs = {}\n",
    "    for width in tqdm(widths):\n",
    "        mysimcovs[width] = np.stack([\n",
    "            simrnn_ntk(inpseqs, width,\n",
    "                       nonlin, varw, varu, varb,\n",
    "                       seed=seed, avgpool=avgpool, debug=False)['ntk']\n",
    "            for seed in range(nseeds)])\n",
    "    frobs = []\n",
    "    infntknorm = np.linalg.norm(infntk)\n",
    "    for width in widths:\n",
    "        _frobs = np.sum((mysimcovs[width] - infntk)**2,\n",
    "                        axis=(1, 2)) / infntknorm**2\n",
    "        for f in _frobs:\n",
    "            frobs.append(dict(\n",
    "                relfrob=np.sqrt(f),\n",
    "                width=width\n",
    "            ))\n",
    "    return pd.DataFrame(frobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We measured the relative Frobenius norm of the finite-width deviation = $\\|\\Theta - \\mathring \\Theta\\|_F / \\|\\mathring \\Theta\\|_F$, where $\\Theta$ and $\\mathring \\Theta$ are resp. the finite (empirical) and infinite-width (theoretical) NTKs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T21:05:30.779105Z",
     "start_time": "2020-06-17T20:58:32.865163Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "38%|███▊      | 3/8 [00:03<00:06,  1.23s/it]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-02829072c7b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m frob_df = NTK_theory_vs_sim(inps, thcov, varw, varu, varb,\n\u001b[0m\u001b[0;32m      2\u001b[0m                            avgpool=True, log2widthmax=14, nseeds=100)\n",
      "\u001b[1;32m<ipython-input-81-79bb64f014a2>\u001b[0m in \u001b[0;36mNTK_theory_vs_sim\u001b[1;34m(inpseqs, infntk, varw, varu, varb, avgpool, nonlin, log2widthmin, log2widthmax, nseeds)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmysimcovs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         mysimcovs[width] = np.stack([\n\u001b[0m\u001b[0;32m     10\u001b[0m             simrnn_ntk(inpseqs, width,\n\u001b[0;32m     11\u001b[0m                        \u001b[0mnonlin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvaru\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-81-79bb64f014a2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         mysimcovs[width] = np.stack([\n\u001b[1;32m---> 10\u001b[1;33m             simrnn_ntk(inpseqs, width,\n\u001b[0m\u001b[0;32m     11\u001b[0m                        \u001b[0mnonlin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvaru\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                        seed=seed, avgpool=avgpool, debug=False)['ntk']\n",
      "\u001b[1;32m<ipython-input-74-3d14408bbd1a>\u001b[0m in \u001b[0;36msimrnn_ntk\u001b[1;34m(inputseqs, width, phi, varw, varu, varb, varv, seed, avgpool, debug)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputseqs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclone_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\netsor\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\netsor\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frob_df = NTK_theory_vs_sim(inps, thcov, varw, varu, varb,\n",
    "                           avgpool=True, log2widthmax=14, nseeds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T21:05:32.092838Z",
     "start_time": "2020-06-17T21:05:30.780738Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'frob_df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-d24dff211c28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrob_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'width'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relfrob'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mwidths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'--'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu'${width}^{-1/2}$'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'Relative Frob. Norm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloglog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frob_df' is not defined"
     ]
    }
   ],
   "source": [
    "sns.lineplot(data=frob_df, x='width', y='relfrob')\n",
    "widths = frob_df.width.unique()\n",
    "plt.plot(widths, np.array(widths, dtype='float')**-0.5, '--', label=u'${width}^{-1/2}$')\n",
    "plt.ylabel(u'Relative Frob. Norm')\n",
    "plt.loglog()\n",
    "plt.legend()\n",
    "_ = plt.title(u'RNN NTK\\nDeviation from theory drops like $width^{-1/2}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T21:05:32.099698Z",
     "start_time": "2020-06-17T21:05:32.094391Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'frob_df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-6305ce963af1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfrob_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rnn_ap_ntk.frob'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'frob_df' is not defined"
     ]
    }
   ],
   "source": [
    "frob_df.to_pickle('rnn_ap_ntk.frob')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('netsor': conda)",
   "language": "python",
   "name": "python38364bitnetsorconda90413646b69740418857320fb86a86c0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}